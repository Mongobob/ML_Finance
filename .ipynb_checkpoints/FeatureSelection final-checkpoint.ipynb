{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.imputation.mice import MICE, MICEData\n",
    "# import fancyimpute\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/mvand/Documents/UZH/FS20/Intro to Machine Learning/Group Project/Clean Mapping.csv\", sep=';',\n",
    "                parse_dates=['adate', 'qdate', 'public_date', 'datadate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29409, 88)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['splticrm'] != 'D']\n",
    "df = df[df['splticrm'] != 'CCC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all rows where splticrm has NA values:\n",
    "df = df[df['splticrm'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3656 1943  990  296 5455 3209  489 3882 4682  199   50  143  382 1069\n",
      " 1648 1096  220]\n",
      "Index(['A', 'A+', 'AA-', 'AAA', 'BBB', 'BBB-', 'AA', 'A-', 'BBB+', 'AA+',\n",
      "       'CCC+', 'B-', 'B+', 'BB-', 'BB+', 'BB', 'B'],\n",
      "      dtype='object')\n",
      "       Rating as Factor\n",
      "0                     0\n",
      "1                     0\n",
      "2                     0\n",
      "3                     0\n",
      "4                     0\n",
      "...                 ...\n",
      "29404                 8\n",
      "29405                 8\n",
      "29406                 8\n",
      "29407                 8\n",
      "29408                 8\n",
      "\n",
      "[29409 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "Y = pd.factorize(df[\"splticrm\"])[0]\n",
    "print(np.bincount(Y))\n",
    "print(pd.factorize(df[\"splticrm\"])[1])\n",
    "Y = pd.DataFrame(Y, columns=[\"Rating as Factor\"])\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>bm</th>\n",
       "      <th>evm</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>pe_exi</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>ps</th>\n",
       "      <th>pcf</th>\n",
       "      <th>dpr</th>\n",
       "      <th>...</th>\n",
       "      <th>sale_nwc</th>\n",
       "      <th>rd_sale</th>\n",
       "      <th>adv_sale</th>\n",
       "      <th>staff_sale</th>\n",
       "      <th>accrual</th>\n",
       "      <th>ptb</th>\n",
       "      <th>PEG_trailing</th>\n",
       "      <th>DIVYIELD</th>\n",
       "      <th>PEG_1yrforward</th>\n",
       "      <th>PEG_ltgforward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>26.386</td>\n",
       "      <td>0.252</td>\n",
       "      <td>10.110</td>\n",
       "      <td>19.217</td>\n",
       "      <td>19.378</td>\n",
       "      <td>20.052</td>\n",
       "      <td>20.052</td>\n",
       "      <td>4.976</td>\n",
       "      <td>13.353</td>\n",
       "      <td>0.129</td>\n",
       "      <td>...</td>\n",
       "      <td>1.894</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058</td>\n",
       "      <td>4.145</td>\n",
       "      <td>1.045</td>\n",
       "      <td>0.00867</td>\n",
       "      <td>2.221</td>\n",
       "      <td>1.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>28.226</td>\n",
       "      <td>0.252</td>\n",
       "      <td>10.110</td>\n",
       "      <td>20.542</td>\n",
       "      <td>20.714</td>\n",
       "      <td>21.435</td>\n",
       "      <td>21.435</td>\n",
       "      <td>5.323</td>\n",
       "      <td>14.285</td>\n",
       "      <td>0.129</td>\n",
       "      <td>...</td>\n",
       "      <td>1.894</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058</td>\n",
       "      <td>4.434</td>\n",
       "      <td>1.117</td>\n",
       "      <td>0.00811</td>\n",
       "      <td>2.058</td>\n",
       "      <td>1.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29.464</td>\n",
       "      <td>0.252</td>\n",
       "      <td>10.110</td>\n",
       "      <td>21.425</td>\n",
       "      <td>21.605</td>\n",
       "      <td>22.357</td>\n",
       "      <td>22.357</td>\n",
       "      <td>5.556</td>\n",
       "      <td>14.911</td>\n",
       "      <td>0.129</td>\n",
       "      <td>...</td>\n",
       "      <td>1.894</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058</td>\n",
       "      <td>4.628</td>\n",
       "      <td>1.165</td>\n",
       "      <td>0.00778</td>\n",
       "      <td>2.146</td>\n",
       "      <td>1.586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28.783</td>\n",
       "      <td>0.233</td>\n",
       "      <td>10.983</td>\n",
       "      <td>21.378</td>\n",
       "      <td>21.556</td>\n",
       "      <td>23.096</td>\n",
       "      <td>23.096</td>\n",
       "      <td>5.381</td>\n",
       "      <td>15.909</td>\n",
       "      <td>0.177</td>\n",
       "      <td>...</td>\n",
       "      <td>1.891</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049</td>\n",
       "      <td>4.515</td>\n",
       "      <td>1.545</td>\n",
       "      <td>0.00773</td>\n",
       "      <td>1.848</td>\n",
       "      <td>1.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>25.096</td>\n",
       "      <td>0.233</td>\n",
       "      <td>10.983</td>\n",
       "      <td>18.653</td>\n",
       "      <td>18.808</td>\n",
       "      <td>20.152</td>\n",
       "      <td>20.152</td>\n",
       "      <td>4.692</td>\n",
       "      <td>13.871</td>\n",
       "      <td>0.177</td>\n",
       "      <td>...</td>\n",
       "      <td>1.891</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049</td>\n",
       "      <td>3.937</td>\n",
       "      <td>1.348</td>\n",
       "      <td>0.00886</td>\n",
       "      <td>1.612</td>\n",
       "      <td>1.432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CAPEI     bm     evm  pe_op_basic  pe_op_dil  pe_exi  pe_inc     ps  \\\n",
       "0  26.386  0.252  10.110       19.217     19.378  20.052  20.052  4.976   \n",
       "1  28.226  0.252  10.110       20.542     20.714  21.435  21.435  5.323   \n",
       "2  29.464  0.252  10.110       21.425     21.605  22.357  22.357  5.556   \n",
       "3  28.783  0.233  10.983       21.378     21.556  23.096  23.096  5.381   \n",
       "4  25.096  0.233  10.983       18.653     18.808  20.152  20.152  4.692   \n",
       "\n",
       "      pcf    dpr  ...  sale_nwc  rd_sale  adv_sale  staff_sale  accrual  \\\n",
       "0  13.353  0.129  ...     1.894    0.120     0.003         0.0    0.058   \n",
       "1  14.285  0.129  ...     1.894    0.120     0.003         0.0    0.058   \n",
       "2  14.911  0.129  ...     1.894    0.120     0.003         0.0    0.058   \n",
       "3  15.909  0.177  ...     1.891    0.121     0.003         0.0    0.049   \n",
       "4  13.871  0.177  ...     1.891    0.121     0.003         0.0    0.049   \n",
       "\n",
       "     ptb  PEG_trailing  DIVYIELD  PEG_1yrforward  PEG_ltgforward  \n",
       "0  4.145         1.045   0.00867           2.221           1.554  \n",
       "1  4.434         1.117   0.00811           2.058           1.520  \n",
       "2  4.628         1.165   0.00778           2.146           1.586  \n",
       "3  4.515         1.545   0.00773           1.848           1.642  \n",
       "4  3.937         1.348   0.00886           1.612           1.432  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != \"splticrm\"]\n",
    "X = X.drop([\"permno\", \"CUSIP\", \"NCUSIP\", \"adate\", \"qdate\", \"public_date\", \"TICKER\"], axis=1)\n",
    "X = X.drop([\"COMNAM\", \"PERMCO\", \"NWPERM\", \"gvkey\", \"datadate\", \"tic\", \"cusip\", \"conm\", \"PRC\"], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAs = X.isnull().sum() > 10000\n",
    "Zeros =  (X == 0).sum() > 10000\n",
    "delNAs = X.columns[NAs] #drops PEG_trailing\n",
    "delZeros= X.columns[Zeros] #drops rd_sale, adv_sale, staff_sale\n",
    "X = X.drop(delNAs, axis=1)\n",
    "X = X.drop(delZeros, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now do the train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0, \n",
    "                                                    stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>bm</th>\n",
       "      <th>evm</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>pe_exi</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>ps</th>\n",
       "      <th>pcf</th>\n",
       "      <th>dpr</th>\n",
       "      <th>...</th>\n",
       "      <th>rect_turn</th>\n",
       "      <th>pay_turn</th>\n",
       "      <th>sale_invcap</th>\n",
       "      <th>sale_equity</th>\n",
       "      <th>sale_nwc</th>\n",
       "      <th>accrual</th>\n",
       "      <th>ptb</th>\n",
       "      <th>DIVYIELD</th>\n",
       "      <th>PEG_1yrforward</th>\n",
       "      <th>PEG_ltgforward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6595</td>\n",
       "      <td>36.03</td>\n",
       "      <td>0.235</td>\n",
       "      <td>12.83</td>\n",
       "      <td>11.986</td>\n",
       "      <td>12.131</td>\n",
       "      <td>13.943</td>\n",
       "      <td>6.876</td>\n",
       "      <td>1.884</td>\n",
       "      <td>13.644</td>\n",
       "      <td>0.334</td>\n",
       "      <td>...</td>\n",
       "      <td>4.891</td>\n",
       "      <td>4.585</td>\n",
       "      <td>1.665</td>\n",
       "      <td>2.794</td>\n",
       "      <td>4.008</td>\n",
       "      <td>0.062</td>\n",
       "      <td>4.444</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CAPEI     bm    evm  pe_op_basic  pe_op_dil  pe_exi  pe_inc     ps  \\\n",
       "6595  36.03  0.235  12.83       11.986     12.131  13.943   6.876  1.884   \n",
       "\n",
       "         pcf    dpr  ...  rect_turn  pay_turn  sale_invcap  sale_equity  \\\n",
       "6595  13.644  0.334  ...      4.891     4.585        1.665        2.794   \n",
       "\n",
       "      sale_nwc  accrual    ptb  DIVYIELD  PEG_1yrforward  PEG_ltgforward  \n",
       "6595     4.008    0.062  4.444    0.0133           0.978           1.281  \n",
       "\n",
       "[1 rows x 67 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAPEI               47\n",
       "bm                 529\n",
       "evm                 76\n",
       "pe_op_basic        274\n",
       "pe_op_dil          278\n",
       "                  ... \n",
       "accrual             28\n",
       "ptb                529\n",
       "DIVYIELD          4003\n",
       "PEG_1yrforward     799\n",
       "PEG_ltgforward    1286\n",
       "Length: 67, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define function for IterativeImputer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "#def iterative_imputer(df):\n",
    "   # \"\"\" Impute the missing values (NaN) with the IterativeImputer\n",
    "    \n",
    "    #Args:\n",
    "     #   df: feature matrix with NaN values to be imputed\n",
    "    #\"\"\"\n",
    "    #Define all column with numeric values (the features)\n",
    "    #num_cols = ['CAPEI', 'bm', 'evm', 'pe_op_basic', 'pe_op_dil', 'pe_exi', 'pe_inc', 'ps', 'pcf', \n",
    "     #       'dpr', 'npm', 'opmbd', 'opmad', 'gpm', 'ptpm', 'cfm', 'roa', 'roe', 'roce', 'efftax', 'aftret_eq',\n",
    "      #      'aftret_invcapx', 'aftret_equity', 'pretret_noa', 'pretret_earnat', 'GProf', 'equity_invcap',\n",
    "       #     'debt_invcap', 'totdebt_invcap', 'capital_ratio', 'int_debt', 'int_totdebt', 'cash_lt', 'invt_act',\n",
    "        ##    'rect_act', 'debt_at', 'debt_ebitda', 'short_debt', 'curr_debt', 'lt_debt', 'profit_lct', 'ocf_lct',\n",
    "          #  'cash_debt', 'fcf_ocf', 'lt_ppent', 'dltt_be', 'debt_assets', 'debt_capital', 'de_ratio', 'intcov',\n",
    "           ## 'intcov_ratio', 'cash_ratio', 'quick_ratio', 'curr_ratio', 'cash_conversion', 'inv_turn', 'at_turn',\n",
    "            #'rect_turn', 'pay_turn', 'sale_invcap', 'sale_equity', 'sale_nwc', 'accrual', 'ptb',\n",
    "            #'DIVYIELD', 'PEG_1yrforward', 'PEG_ltgforward']\n",
    "\n",
    "    # Copy df to df_imputed\n",
    "    #df_imputed = df[num_cols].copy(deep=True)\n",
    "\n",
    "    # Initialize IterativeImputer\n",
    "    #mice_imputer = IterativeImputer()\n",
    "\n",
    "    # Impute using fit_tranform on df\n",
    "    #df_imputed.iloc[:, :] = mice_imputer.fit_transform(df[num_cols])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply IterativeImputer\n",
    "### here I still have to implement the correct function\n",
    "\n",
    "num_cols = ['CAPEI', 'bm', 'evm', 'pe_op_basic', 'pe_op_dil', 'pe_exi', 'pe_inc', 'ps', 'pcf', \n",
    "            'dpr', 'npm', 'opmbd', 'opmad', 'gpm', 'ptpm', 'cfm', 'roa', 'roe', 'roce', 'efftax', 'aftret_eq',\n",
    "            'aftret_invcapx', 'aftret_equity', 'pretret_noa', 'pretret_earnat', 'GProf', 'equity_invcap',\n",
    "            'debt_invcap', 'totdebt_invcap', 'capital_ratio', 'int_debt', 'int_totdebt', 'cash_lt', 'invt_act',\n",
    "            'rect_act', 'debt_at', 'debt_ebitda', 'short_debt', 'curr_debt', 'lt_debt', 'profit_lct', 'ocf_lct',\n",
    "            'cash_debt', 'fcf_ocf', 'lt_ppent', 'dltt_be', 'debt_assets', 'debt_capital', 'de_ratio', 'intcov',\n",
    "            'intcov_ratio', 'cash_ratio', 'quick_ratio', 'curr_ratio', 'cash_conversion', 'inv_turn', 'at_turn',\n",
    "            'rect_turn', 'pay_turn', 'sale_invcap', 'sale_equity', 'sale_nwc', 'accrual', 'ptb',\n",
    "            'DIVYIELD', 'PEG_1yrforward', 'PEG_ltgforward']\n",
    "\n",
    "# Copy df to df_mice_imputed\n",
    "X_train_imputed = X_train[num_cols].copy(deep=True)\n",
    "\n",
    "# Initialize IterativeImputer\n",
    "mice_imputer = IterativeImputer()\n",
    "\n",
    "# Impute using fit_tranform on diabetes\n",
    "X_train_imputed.iloc[:, :] = mice_imputer.fit_transform(X_train[num_cols])\n",
    "\n",
    "# Copy df to df_mice_imputed\n",
    "X_test_imputed = X_test[num_cols].copy(deep=True)\n",
    "\n",
    "# Initialize IterativeImputer\n",
    "mice_imputer = IterativeImputer()\n",
    "\n",
    "# Impute using fit_tranform on diabetes\n",
    "X_test_imputed.iloc[:, :] = mice_imputer.transform(X_test[num_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the missing values with IterativeImputer\n",
    "\n",
    "#X_train_imputed = iterative_imputer(dataframe=X_train)\n",
    "#X_test_imputed = iterative_imputer(dataframe=X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def feature_selection(x, y, n):\n",
    "    \"\"\" Find out, which the most important features are.\n",
    "    \n",
    "    Args:\n",
    "        x: feature input without NaN values\n",
    "        y: classification input\n",
    "        n: number of most important features, that need to be calculated\n",
    "    \"\"\"\n",
    "    \n",
    "    feat_labels = x.columns[:]\n",
    "    \n",
    "    # Create Random Forest object, fit data and\n",
    "    # extract feature importance attributes\n",
    "    forest = RandomForestClassifier(random_state=1)\n",
    "    forest.fit(x, y)\n",
    "    importances = forest.feature_importances_\n",
    "    \n",
    "    # Get cumsum of the n most important features\n",
    "    feat_imp = np.sort(importances)[::-1]\n",
    "    sum_feat_imp = np.cumsum(feat_imp)[:n]\n",
    "    \n",
    "     # Sort output (by relative importance) and \n",
    "    # print top n features\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    for i in range(n):\n",
    "        print('{0:2d}) {1:7s} {2:6.4f}'.format(i + 1, \n",
    "                                           feat_labels[indices[i]],\n",
    "                                           importances[indices[i]]))\n",
    "    \n",
    "    # Plot Feature Importance (both cumul., individual)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(range(n), importances[indices[:n]], align='center')\n",
    "    plt.xticks(range(n), feat_labels[indices[:n]], rotation=90)\n",
    "    plt.xlim([-1, n])\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Rel. Feature Importance')\n",
    "    plt.step(range(n), sum_feat_imp, where='mid', \n",
    "         label='Cumulative importance')\n",
    "    plt.tight_layout();\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection(x = X_train_imputed, y = y_train, n = 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
