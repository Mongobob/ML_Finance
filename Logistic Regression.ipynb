{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_train = X_train.iloc[:, 1:]\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "X_test = X_test.iloc[:, 1:]\n",
    "Y_train = pd.read_csv(\"y_train.csv\")\n",
    "Y_test = pd.read_csv(\"y_test.csv\")\n",
    "Y_train = Y_train['Rating as Factor'].astype('category') #factorize trainset\n",
    "Y_test = Y_test['Rating as Factor'].astype('category')   #factorize testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg(X_train, Y_train):\n",
    "    '''\n",
    "    X_train: Training Set of X values\n",
    "    Y_train: Training Set of Y values(factorized)\n",
    "    '''\n",
    "    lor = LogisticRegression(max_iter=100, tol=0.001,random_state=1, n_jobs=-1,solver='saga',warm_start=True) #increasing iterations to 1000 increases score by only 1% -> it is not worth the additional time\n",
    "\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                     ('logreg', lor)])\n",
    "\n",
    "    param_grid = {'logreg__penalty': ['elasticnet'], #elastic nets combines l1&l2\n",
    "                  'logreg__C':[6,6.5,7,7.5,8],\n",
    "                  'logreg__l1_ratio':[0,0.05,0.1,0.15,0.2,1]} #if 0, or 1 then l2 or l1 would be best. If between then the combination of both\n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "    grid = grid.fit(X_train,Y_train)\n",
    "    \n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-03 10:58:40.268725\n",
      "Best parameters: {'logreg__C': 7, 'logreg__l1_ratio': 0, 'logreg__penalty': 'elasticnet'}\n",
      "Best CV accuracy: 0.3027588539829543\n",
      "Test score: 0.31009860591635496\n",
      "2020-04-03 11:05:11.087937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programme\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "grid = LogReg(X_train,Y_train)\n",
    "print('Best parameters:', grid.best_params_) #best parameters are C=7 & ratio=0 -> l2 penalty function\n",
    "print('Best CV accuracy:', grid.best_score_)\n",
    "print('Test score:', grid.score(X_test,Y_test)) #30%\n",
    "print(datetime.datetime.now()) #took my computer 5minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0    1   2   3    4    5   6    7    8   11  12  13  14  15  16\n",
      "True                                                                       \n",
      "0          234   36   9   0  230   13   0   68  137   0   0   0   0   4   0\n",
      "1           62  135  15   0   66   19   1   16   73   0   0   0   0   2   0\n",
      "2           89   21  16   0   20    4   2    4   42   0   0   0   0   0   0\n",
      "3           17   26   4  11    0    0   0    0    1   0   0   0   0   0   0\n",
      "4           94   51   3   0  636   46   2   38  183   0   1  18   6  13   0\n",
      "5           65   25   9   1  290  104   3   16   97   0   0  16  11   5   0\n",
      "6           12   19   1   6   20    0  15    9   16   0   0   0   0   0   0\n",
      "7           84   32   0   0  294    6   0  206  150   0   0   2   1   1   0\n",
      "8           73   49   8   0  390   35   0   72  285   0   1   7  10   5   1\n",
      "9           22    0   0   0    0    0   0   10    8   0   0   0   0   0   0\n",
      "10           0    0   0   0    3    0   0    0    0   0   0   7   0   0   0\n",
      "11           0    0   2   0    4    0   0    1    0   0   0  15   0   0   7\n",
      "12           0    0   0   0   10    0   1    2    0   1  14  32  10   6   0\n",
      "13           2    3   4   0   72    9   2    1   16   0   8  79   3  15   0\n",
      "14          28   19   7   0  153   21   3    5   30   0   4  14  44   2   0\n",
      "15           5    6   0   0   95   21   0    9   18   0   0  16   7  42   0\n",
      "16           0    2   0   0    9    0   0    3    0   0   0  26   1   0   3\n"
     ]
    }
   ],
   "source": [
    "# Predict classes\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Manual confusion matrix as pandas DataFrame\n",
    "confm = pd.DataFrame({'Predicted': y_pred,\n",
    "                      'True': Y_test})\n",
    "print(confm.groupby(['True','Predicted'], sort=True).size().unstack('Predicted')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
