{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_train = X_train.iloc[:, 1:]\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "X_test = X_test.iloc[:, 1:]\n",
    "Y_train = pd.read_csv(\"y_train.csv\")\n",
    "Y_test = pd.read_csv(\"y_test.csv\")\n",
    "Y_train = Y_train['Rating as Factor'].astype('category') #factorize trainset\n",
    "Y_test = Y_test['Rating as Factor'].astype('category')   #factorize testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg(X_train, Y_train):\n",
    "    '''\n",
    "    X_train: Training Set of X values\n",
    "    Y_train: Training Set of Y values(factorized)\n",
    "    '''\n",
    "    lor = LogisticRegression(max_iter=100, tol=0.001,random_state=1, n_jobs=-1,solver='saga',warm_start=True)\n",
    "\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                     ('logreg', lor)])\n",
    "\n",
    "    param_grid = {'logreg__penalty': ['elasticnet'], #elastic nets combines l1&l2\n",
    "                  'logreg__C':[6,6.5,7,7.5,8],\n",
    "                  'logreg__l1_ratio':[0,0.05,0.1,0.15,0.2,1]} #if 0, or 1 then l2 or l1 would be best. If between then the combination of both\n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "    grid = grid.fit(X_train,Y_train)\n",
    "    \n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-02 19:16:12.846335\n",
      "Best parameters: {'logreg__C': 7, 'logreg__l1_ratio': 0, 'logreg__penalty': 'elasticnet'}\n",
      "Best CV accuracy: 0.3027588539829543\n",
      "Test score: 0.31009860591635496\n",
      "2020-04-02 19:22:40.639718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programme\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "grid = LogReg(X_train,Y_train)\n",
    "print('Best parameters:', grid.best_params_) #best parameters are C=7 & ratio=0 -> l2 penalty function\n",
    "print('Best CV accuracy:', grid.best_score_)\n",
    "print('Test score:', grid.score(X_test,Y_test)) #30%\n",
    "print(datetime.datetime.now()) #took my computer 5minutes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
