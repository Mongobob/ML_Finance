{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_train = X_train.iloc[:, 1:]\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "X_test = X_test.iloc[:, 1:]\n",
    "Y_train = pd.read_csv(\"y_train.csv\")\n",
    "Y_test = pd.read_csv(\"y_test.csv\")\n",
    "Y_train = Y_train['Rating as Factor'].astype('category') #factorize trainset\n",
    "Y_test = Y_test['Rating as Factor'].astype('category')   #factorize testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg(X_train, Y_train):\n",
    "    '''\n",
    "    X_train: Training Set of X values\n",
    "    Y_train: Training Set of Y values(factorized)\n",
    "    '''\n",
    "    lor = LogisticRegression(max_iter=100, tol=0.001,random_state=1, n_jobs=-1,solver='saga',warm_start=True)\n",
    "\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                     ('logreg', lor)])\n",
    "\n",
    "    param_grid = {'logreg__penalty': ['elasticnet'], #elastic nets combines l1&l2\n",
    "                  'logreg__C':[6,6.5,7,7.5,8],\n",
    "                  'logreg__l1_ratio':[0,0.05,0.1,0.15,0.2,1]} #if 0, or 1 then l2 or l1 would be best. If between then the combination of both\n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "    grid = grid.fit(X_train,Y_train)\n",
    "    \n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-02 19:16:12.846335\n",
      "Best parameters: {'logreg__C': 7, 'logreg__l1_ratio': 0, 'logreg__penalty': 'elasticnet'}\n",
      "Best CV accuracy: 0.3027588539829543\n",
      "Test score: 0.31009860591635496\n",
      "2020-04-02 19:22:40.639718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programme\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "grid = LogReg(X_train,Y_train)\n",
    "print('Best parameters:', grid.best_params_) #best parameters are C=7 & ratio=0 -> l2 penalty function\n",
    "print('Best CV accuracy:', grid.best_score_)\n",
    "print('Test score:', grid.score(X_test,Y_test)) #30%\n",
    "print(datetime.datetime.now()) #took my computer 5minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg(X_train, Y_train):\n",
    "    '''\n",
    "    X_train: Training Set of X values\n",
    "    Y_train: Training Set of Y values(factorized)\n",
    "    '''\n",
    "    lor = LogisticRegression(max_iter=100, tol=0.001,random_state=1, n_jobs=-1,solver='saga',warm_start=True)\n",
    "\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                     ('logreg', lor)])\n",
    "\n",
    "    param_grid = {'logreg__penalty': ['elasticnet'], #elastic nets combines l1&l2\n",
    "                  'logreg__C':[6.5,7,7.5],\n",
    "                  'logreg__l1_ratio':[0,0.1,0.2,1]} #if 0, or 1 then l2 or l1 would be best. If between then the combination of both\n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "    grid = grid.fit(X_train,Y_train)\n",
    "    \n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-03 09:20:26.180019\n",
      "Best parameters: {'logreg__C': 7, 'logreg__l1_ratio': 0, 'logreg__penalty': 'elasticnet'}\n",
      "Best CV accuracy: 0.3103246674943647\n",
      "Test score: 0.3151989119347161\n",
      "2020-04-03 09:22:48.130018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mvand\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "grid = LogReg(X_train,Y_train)\n",
    "print('Best parameters:', grid.best_params_) #best parameters are C=7 & ratio=0 -> l2 penalty function\n",
    "print('Best CV accuracy:', grid.best_score_)\n",
    "print('Test score:', grid.score(X_test,Y_test)) #30%\n",
    "print(datetime.datetime.now()) #took my computer 5minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted     0      1     2     3      4      5     6      7      8    11  \\\n",
      "True                                                                         \n",
      "0          241.0   35.0   9.0   NaN  216.0   12.0   NaN   71.0  143.0  NaN   \n",
      "1           60.0  127.0  23.0   NaN   68.0   17.0   4.0   15.0   72.0  NaN   \n",
      "2           84.0   20.0  24.0   NaN   20.0    2.0   2.0    NaN   45.0  NaN   \n",
      "3           19.0   16.0   4.0  16.0    NaN    NaN   3.0    NaN    1.0  NaN   \n",
      "4           94.0   50.0   3.0   1.0  631.0   41.0   1.0   44.0  182.0  NaN   \n",
      "5           65.0   25.0   8.0   2.0  278.0  110.0   4.0   16.0  100.0  NaN   \n",
      "6           10.0   11.0   9.0   5.0   20.0    NaN  21.0    7.0   15.0  NaN   \n",
      "7           93.0   25.0   5.0   NaN  282.0    6.0   2.0  211.0  148.0  NaN   \n",
      "8           72.0   47.0   6.0   2.0  389.0   34.0   NaN   76.0  285.0  NaN   \n",
      "9           23.0    NaN   NaN   NaN    NaN    NaN   NaN   10.0    7.0  NaN   \n",
      "10           NaN    NaN   NaN   NaN    3.0    NaN   NaN    NaN    NaN  3.0   \n",
      "11           NaN    NaN   2.0   NaN    5.0    NaN   NaN    NaN    NaN  NaN   \n",
      "12           NaN    NaN   NaN   NaN   10.0    NaN   1.0    2.0    NaN  1.0   \n",
      "13           2.0    1.0   5.0   NaN   68.0   10.0   2.0    2.0   15.0  NaN   \n",
      "14          30.0   19.0   4.0   NaN  146.0   24.0   4.0    8.0   33.0  NaN   \n",
      "15           4.0    7.0   NaN   NaN   92.0   23.0   NaN    9.0   14.0  NaN   \n",
      "16           NaN    1.0   NaN   NaN    9.0    NaN   NaN    3.0    NaN  NaN   \n",
      "\n",
      "Predicted    12    13    14    15   16  \n",
      "True                                    \n",
      "0           NaN   NaN   NaN   4.0  NaN  \n",
      "1           NaN   NaN   1.0   2.0  NaN  \n",
      "2           NaN   NaN   NaN   1.0  NaN  \n",
      "3           NaN   NaN   NaN   NaN  NaN  \n",
      "4           NaN  20.0   9.0  15.0  NaN  \n",
      "5           NaN  17.0   8.0   9.0  NaN  \n",
      "6           NaN   NaN   NaN   NaN  NaN  \n",
      "7           NaN   2.0   1.0   1.0  NaN  \n",
      "8           NaN   8.0  11.0   5.0  1.0  \n",
      "9           NaN   NaN   NaN   NaN  NaN  \n",
      "10          NaN   3.0   NaN   NaN  1.0  \n",
      "11          NaN  15.0   NaN   NaN  7.0  \n",
      "12         15.0  32.0   9.0   6.0  NaN  \n",
      "13          8.0  81.0   4.0  16.0  NaN  \n",
      "14          4.0  14.0  42.0   2.0  NaN  \n",
      "15          NaN  18.0   7.0  44.0  1.0  \n",
      "16          NaN  24.0   1.0   NaN  6.0  \n"
     ]
    }
   ],
   "source": [
    "# Predict classes\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Manual confusion matrix as pandas DataFrame\n",
    "confm = pd.DataFrame({'Predicted': y_pred,\n",
    "                      'True': Y_test})\n",
    "print(confm.groupby(['True','Predicted'], sort=True).size().unstack('Predicted')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
